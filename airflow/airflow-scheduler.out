[[34m2023-06-08 23:00:00,524[0m] {[34mscheduler_job.py:[0m714} INFO[0m - Starting the scheduler[0m
[[34m2023-06-08 23:00:00,536[0m] {[34mscheduler_job.py:[0m719} INFO[0m - Processing each file at most -1 times[0m
[[34m2023-06-08 23:00:00,542[0m] {[34mexecutor_loader.py:[0m107} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2023-06-08 23:00:00,552[0m] {[34mmanager.py:[0m163} INFO[0m - Launched DagFileProcessorManager with pid: 4646[0m
[[34m2023-06-08 23:00:00,568[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-08 23:00:00,582[0m] {[34msettings.py:[0m58} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2023-06-08T23:00:00.616+0000] {manager.py:409} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2023-06-08 23:05:00,725[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-08 23:10:00,757[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-08 23:15:00,819[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-08 23:20:00,849[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-08 23:25:00,896[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-08 23:30:00,934[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-08 23:35:00,967[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-08 23:40:01,011[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-08 23:43:17,268[0m] {[34mscheduler_job.py:[0m360} INFO[0m - 1 tasks up for execution:
	<TaskInstance: transform_dag.transform_task manual__2023-06-08T23:43:16.394086+00:00 [scheduled]>[0m
[[34m2023-06-08 23:43:17,268[0m] {[34mscheduler_job.py:[0m425} INFO[0m - DAG transform_dag has 0/16 running and queued tasks[0m
[[34m2023-06-08 23:43:17,269[0m] {[34mscheduler_job.py:[0m511} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: transform_dag.transform_task manual__2023-06-08T23:43:16.394086+00:00 [scheduled]>[0m
[[34m2023-06-08 23:43:17,271[0m] {[34mscheduler_job.py:[0m550} INFO[0m - Sending TaskInstanceKey(dag_id='transform_dag', task_id='transform_task', run_id='manual__2023-06-08T23:43:16.394086+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-06-08 23:43:17,271[0m] {[34mbase_executor.py:[0m93} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'transform_dag', 'transform_task', 'manual__2023-06-08T23:43:16.394086+00:00', '--local', '--subdir', 'DAGS_FOLDER/transform_dag.py'][0m
[[34m2023-06-08 23:43:17,299[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'transform_dag', 'transform_task', 'manual__2023-06-08T23:43:16.394086+00:00', '--local', '--subdir', 'DAGS_FOLDER/transform_dag.py'][0m
[[34m2023-06-08 23:43:21,103[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/transform_dag.py[0m
[[34m2023-06-08 23:43:21,363[0m] {[34mexample_kubernetes_executor.py:[0m41} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-06-08 23:43:21,404[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(BashOperator): create_entry_group>, delete_entry_group already registered for DAG: example_complex[0m
[[34m2023-06-08 23:43:21,404[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(BashOperator): delete_entry_group>, create_entry_group already registered for DAG: example_complex[0m
[[34m2023-06-08 23:43:21,404[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(BashOperator): create_entry_gcs>, delete_entry already registered for DAG: example_complex[0m
[[34m2023-06-08 23:43:21,404[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(BashOperator): delete_entry>, create_entry_gcs already registered for DAG: example_complex[0m
[[34m2023-06-08 23:43:21,405[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(BashOperator): create_tag>, delete_tag already registered for DAG: example_complex[0m
[[34m2023-06-08 23:43:21,405[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(BashOperator): delete_tag>, create_tag already registered for DAG: example_complex[0m
[[34m2023-06-08 23:43:21,431[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/usr/local/python/3.10.4/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-06-08 23:43:21,431[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-06-08 23:43:21,434[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(_PythonDecoratedOperator): print_the_context>, log_sql_query already registered for DAG: example_python_operator[0m
[[34m2023-06-08 23:43:21,435[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(_PythonDecoratedOperator): log_sql_query>, print_the_context already registered for DAG: example_python_operator[0m
[[34m2023-06-08 23:43:21,435[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(_PythonDecoratedOperator): print_the_context>, log_sql_query already registered for DAG: example_python_operator[0m
[[34m2023-06-08 23:43:21,435[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(_PythonDecoratedOperator): log_sql_query>, print_the_context already registered for DAG: example_python_operator[0m
[[34m2023-06-08 23:43:21,436[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(_PythonDecoratedOperator): print_the_context>, log_sql_query already registered for DAG: example_python_operator[0m
[[34m2023-06-08 23:43:21,436[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(_PythonDecoratedOperator): log_sql_query>, print_the_context already registered for DAG: example_python_operator[0m
[[34m2023-06-08 23:43:21,436[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(_PythonDecoratedOperator): print_the_context>, log_sql_query already registered for DAG: example_python_operator[0m
[[34m2023-06-08 23:43:21,437[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(_PythonDecoratedOperator): log_sql_query>, print_the_context already registered for DAG: example_python_operator[0m
[[34m2023-06-08 23:43:23,132[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(_PythonDecoratedOperator): prepare_email>, send_email already registered for DAG: example_dag_decorator[0m
[[34m2023-06-08 23:43:23,132[0m] {[34mtaskmixin.py:[0m205} WARNING[0m - Dependency <Task(EmailOperator): send_email>, prepare_email already registered for DAG: example_dag_decorator[0m
[[34m2023-06-08 23:43:23,160[0m] {[34mtask_command.py:[0m388} INFO[0m - Running <TaskInstance: transform_dag.transform_task manual__2023-06-08T23:43:16.394086+00:00 [queued]> on host codespaces-abffa2[0m
[[34m2023-06-08 23:43:24,256[0m] {[34mscheduler_job.py:[0m602} INFO[0m - Executor reports execution of transform_dag.transform_task run_id=manual__2023-06-08T23:43:16.394086+00:00 exited with status success for try_number 1[0m
[[34m2023-06-08 23:43:24,262[0m] {[34mscheduler_job.py:[0m645} INFO[0m - TaskInstance Finished: dag_id=transform_dag, task_id=transform_task, run_id=manual__2023-06-08T23:43:16.394086+00:00, map_index=-1, run_start_date=2023-06-08 23:43:23.397195+00:00, run_end_date=2023-06-08 23:43:23.635277+00:00, run_duration=0.238082, state=success, executor_state=success, try_number=1, max_tries=0, job_id=2, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-06-08 23:43:17.269475+00:00, queued_by_job_id=1, pid=26030[0m
[[34m2023-06-08 23:43:24,346[0m] {[34mdagrun.py:[0m607} INFO[0m - Marking run <DagRun transform_dag @ 2023-06-08 23:43:16.394086+00:00: manual__2023-06-08T23:43:16.394086+00:00, state:running, queued_at: 2023-06-08 23:43:16.454851+00:00. externally triggered: True> successful[0m
[[34m2023-06-08 23:43:24,347[0m] {[34mdagrun.py:[0m658} INFO[0m - DagRun Finished: dag_id=transform_dag, execution_date=2023-06-08 23:43:16.394086+00:00, run_id=manual__2023-06-08T23:43:16.394086+00:00, run_start_date=2023-06-08 23:43:17.193521+00:00, run_end_date=2023-06-08 23:43:24.346994+00:00, run_duration=7.153473, state=success, external_trigger=True, run_type=manual, data_interval_start=2023-06-08 23:43:16.394086+00:00, data_interval_end=2023-06-08 23:43:16.394086+00:00, dag_hash=a088b9e73acede6cf09fcc793625fa96[0m
[[34m2023-06-08 23:43:24,351[0m] {[34mdag.py:[0m3437} INFO[0m - Setting next_dagrun for transform_dag to None, run_after=None[0m
[[34m2023-06-08 23:45:01,055[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-08 23:50:01,087[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-08 23:55:01,121[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2023-06-09 00:00:01,156[0m] {[34mscheduler_job.py:[0m1408} INFO[0m - Resetting orphaned tasks for active dag runs[0m
